{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4925c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3942761a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115393\n"
     ]
    }
   ],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c43ca52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "voc_size = len(chars)\n",
    "d_model=32\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8743aa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {char:i for i,char in enumerate(chars)}\n",
    "itos = {i:char for i,char in enumerate(chars)}\n",
    "encode = lambda char : [stoi[c] for c in char]\n",
    "decode = lambda num : [itos[n] for n in num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79822f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115393])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db5d2a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "validation_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bce98864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[52, 53, 58,  1, 53, 59, 56,  1],\n",
      "        [ 1, 41, 53, 51, 43, 57,  1, 58],\n",
      "        [61, 39, 49, 43,  6,  1, 39, 52],\n",
      "        [ 1, 42, 53, 58, 46,  1, 51, 63]]) tensor([[53, 58,  1, 53, 59, 56,  1, 56],\n",
      "        [41, 53, 51, 43, 57,  1, 58, 46],\n",
      "        [39, 49, 43,  6,  1, 39, 52, 42],\n",
      "        [42, 53, 58, 46,  1, 51, 63,  1]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(mode = 'train'):\n",
    "    data = train_data if mode=='train' else 'validation_data'\n",
    "    ix = torch.randint(len(data)-batch_size, (batch_size,))\n",
    "    d = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    l = torch.stack([data[i+1: i+block_size+1] for i in ix])\n",
    "    return d,l\n",
    "\n",
    "x,y = get_batch()\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "821b4bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size, d_model):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(voc_size, d_model)\n",
    "        self.dim = d_model\n",
    "    def forward(self,x):\n",
    "        x = self.emb(x)\n",
    "        return x * math.sqrt(self.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c19e4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self, seq_length, d_model):\n",
    "        super().__init__()\n",
    "        self.range = torch.arange(seq_length).unsqueeze(1)\n",
    "        even_i = torch.pow(10000, torch.arange(0,d_model,2,dtype=torch.float) / math.sqrt(d_model))\n",
    "        odd_i = torch.pow(10000, torch.arange(1,d_model,2,dtype=torch.float) / math.sqrt(d_model))\n",
    "        self.pe = torch.zeros(seq_length, d_model)\n",
    "        self.pe[:, 0::2] = torch.sin(self.range / even_i)\n",
    "        self.pe[:, 1::2] = torch.cos(self.range / odd_i)   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        b,t,c = x.shape\n",
    "        return x + self.pe[:t,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6f310045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.randn(1))\n",
    "        self.beta = nn.Parameter(torch.randn(1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        std = x.std(dim=-1, keepdim=True)\n",
    "        return self.alpha*(x-mean/(std**2 + 1e-6)) + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1f501dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, p=0.2):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p),\n",
    "            nn.Linear(d_model*4, d_model)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c1f8e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnection(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, p=0.2):\n",
    "        super().__init__()\n",
    "        self.norm = LayerNorm()\n",
    "        self.drop = nn.Dropout(p)\n",
    "        \n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.drop(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "da7da636",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MuliHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, n_head, p=0.2):\n",
    "        super().__init__()\n",
    "        self.w_q = nn.Linear(d_model, d_model, bias = False)\n",
    "        self.w_k = nn.Linear(d_model, d_model, bias = False)        \n",
    "        self.w_v = nn.Linear(d_model, d_model, bias = False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.head = n_head\n",
    "        self.d_model = d_model\n",
    "        self.drop = nn.Dropout(p)\n",
    "    \n",
    "    @staticmethod\n",
    "    def attention(q,k,v,t, d_model, mask):\n",
    "        qk = q @ k.transpose(-1,-2) / math.sqrt(d_model)\n",
    "        wei = qk.masked_fill(mask[:t,:t]==0, float('-inf'))\n",
    "        wei = wei.softmax(dim=-1)\n",
    "\n",
    "        atten = wei @ v\n",
    "        return atten\n",
    "    \n",
    "    def forward(self,x):\n",
    "        b,t,c= x.shape\n",
    "        q = self.w_q(x)\n",
    "        k = self.w_k(x)\n",
    "        v = self.w_v(x)\n",
    "        q = q.view(b, t, self.head, int(c/self.head)).transpose(1,2)\n",
    "        k = k.view(b, t, self.head, int(c/self.head)).transpose(1,2)\n",
    "        v = v.view(b, t, self.head, int(c/self.head)).transpose(1,2)\n",
    "        attention = MuliHead.attention(q,k,v,t, self.d_model, self.tril)\n",
    "        attention = attention.transpose(1,2).contiguous().view(b, t, c)\n",
    "        return self.drop(attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c434fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block = nn.ModuleList([ResidualConnection(d_model) for i in range(2)])\n",
    "        self.head = MuliHead(d_model, 4)\n",
    "        self.ff = FFLayer(d_model)\n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.block[0](x, self.head)\n",
    "        x = self.block[1](x, self.ff)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5841b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projection(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(d_model, voc_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.linear(x)\n",
    "        return torch.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "76a3c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.decode = nn.ModuleList([Block(d_model) for i in range(6)])\n",
    "        self.norm = LayerNorm()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        for d in self.decode:\n",
    "            x = d(x)\n",
    "            \n",
    "        x = self.norm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "cc12d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM(nn.Module):\n",
    "    \n",
    "    def __init__(self, voc_size):\n",
    "        super().__init__()\n",
    "        self.emb = InputEmbedding(voc_size,d_model)\n",
    "        self.pos_emb = PositionEmbedding(block_size, d_model)\n",
    "        self.decode = Decoder(d_model)\n",
    "        self.proj = Projection()\n",
    "    def forward(self,x, target=None):\n",
    "        \n",
    "        b,t = x.shape\n",
    "        x = self.pos_emb(self.emb(x))\n",
    "        y = self.decode(x)\n",
    "        y = self.proj(y)\n",
    "        if target == None:\n",
    "            loss = None\n",
    "            \n",
    "        else:\n",
    "            b, t, c = y.shape\n",
    "            y = y.view(b*t,c)\n",
    "            target = target.view(b*t)\n",
    "            loss = F.nll_loss(y, target)\n",
    "            \n",
    "        return y,loss\n",
    "    \n",
    "    def generate(self, idx, max_new_token):\n",
    "#         idx: (B,T)\n",
    "        for i in range(max_new_token):\n",
    "#         logit: (B,T,C)\n",
    "            logit, loss = self(idx[:, -(block_size):])\n",
    "#         logit: (B,C)\n",
    "            logit = logit[:, -1, :]\n",
    "    #     logit: (B, C)\n",
    "           \n",
    "            logit = F.softmax(logit, dim=-1)\n",
    "    #     logit: (B, 1)\n",
    "            nxt= torch.multinomial(logit, num_samples=1)\n",
    "            idx = torch.concat([idx, nxt], dim=-1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "dd867c2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = LLM(voc_size)\n",
    "logits, loss = m(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7c268774",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.AdamW(m.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "740a632e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3864, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "for i in range(epochs):\n",
    "    xb, yb = get_batch()\n",
    "    logits, loss = m(xb, yb)\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "0e67fbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Thtereccire masancdy you.\n",
      "RELI e--vincffe nyovouf se to'r flekeells,\n",
      "Pumhe eronth, wht hy agh.\n",
      "CUCI ATIURHTRYVELELYRY:\n",
      "Nong andcarer i, trt fiavend frowhe the a po thist ller buno's g in.\n",
      "\n",
      "Moveng mar.  WAickAnengeid ies heverert, whhe f acoric sher,\n",
      "Geny b,y.\n",
      "\n",
      "\n",
      "3e lasb fe usis as weano my rpe ipe. BRENCUif s:\n",
      "Mime hi, ofl aly pamststagus, to thy tathe renerlb sot o he gromeis kiretutver.\n",
      "\n",
      "LORORUERERRS:\n",
      "\n",
      "Mhow toesey'tembur wen cotheeve wigl h;\n",
      "Saschce turmigor rouphe, lashtt sinse thou\n",
      "Eve pisha heren,\n",
      "Ay me t Jeseends?\n",
      "Anty divetu a iste, she mo met d the, te Mussooted ien,\n",
      "A's thabr aimev thim kans, greleache wilan weay we athe ngreean, pthere thin, wiorn the douends; withou ane wit's,\n",
      "Nthe,, ghiny \n",
      "uthit ker our\n",
      "And?\n",
      "\n",
      "LULORCA:\n",
      "MLAVour tondercucpeveting;\n",
      "The,-cy imy arfar.\n",
      "Foch fealleS INO,\n",
      "Endgou sus vinds, osandel onouthe vu,\n",
      "Pons, Fid ghtoro oun urpucctoI d il coenoy seshooMorte mMded osrdm,\n",
      "Hothe cal,\n",
      "Heere Ifioitl kerim klexie, f fugourf.\n",
      "\n",
      "Touoy nofere.\n",
      "C lalle!\n",
      "\n",
      "WOf Yoritemy, a toetus teenr--mireteay ll noveat she finth t rionas hilay oury,\n",
      "my, andr awil thif ndas estt?\n",
      "\n",
      "Hath On p ow jlites tray stheal ca\n",
      "Aim byristonked hel dalethith dar dis thhe de tovay fid\n",
      "lef thathhe mre sothersowe thifrr!\n",
      "The enr,:\n",
      "Pnos:\n",
      "Oof, layt walkins: youu imaatth\n",
      "Le futhever\n",
      "Firelarsit hey aind a the I Ocuse mik\n",
      "Sy botPl ses\n",
      "Myouthe.\n",
      "\n",
      "Fcatr whe bsoy atht; bould angest\n",
      "Iflove ghitaghf hy Asopl RLARD:\n",
      "\n",
      "Thim.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "QU:\n",
      "The the see baremened ad of bepe ovine, gry we. VinghRo mand tha ye buar'th, Bras inghoum pe sir Exod irallfie, doowmplel:\n",
      "ARe  miof tome, ite demthesis my pingh. tis I pinamy Ay\n",
      "pin tour srres shatlluss you congandnkit  adrf or triroouge her spee flity's, pedrre wes l t mand hirg\n",
      "Kk fon,\n",
      "Wo njo he-mar's,\n",
      "Whas m mulake, tules?\n",
      "\n",
      "\n",
      "\n",
      "I he win ullfm,\n",
      "I her ach\n",
      "Hay ce lethen his sooreyr oou, and--ddaues ycon;\n",
      "and: toup towr ma whainer thoblo doalle leve arthe einkerr your menisise proul and ice; ak\n",
      "MENod,ere,\n",
      "Mor iganot: bo kio a ownonger chin f tit udse\n",
      "Fo, e tilifor, siwre \n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long)\n",
    "a =decode(m.generate(context, max_new_token=2000)[0].tolist())\n",
    "print(''.join(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f8a733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
